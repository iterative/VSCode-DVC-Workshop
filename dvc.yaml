## [PIPELINE STAGES](https://dvc.org/doc/user-guide/pipelines/defining-pipelines#defining-pipelines)

# What are stages ?

## Each one of the data workflows that
## we reproduce reliably to ensure consistent results.
## Might include Feature engineering , train , evaluation

# How are stages defined ?

## The stages entries are
##    cmd: python path that wraps executable shell command.
##    params: loads parameters. Related to params.yaml file
##    deps: dependencies. Might contain Stages that might be executed first
##    outs: outputs, they can be data or even the model

# What do you need to set up your experiments ?

## For setting up the experiments, we are going to follow the data science
## cookie template and we are going to use the folders already given. 


stages:
    load:
        cmd: python ExperimentsDVC/src/data/load_dataset.py 

    featureselection:
        cmd: python ExperimentsDVC/src/features/feature_selection.py
        params:
            - featureselection.features
            - featureselection.labels 
        deps: 
        - ExperimentsDVC/src/data/load_dataset.py 
        outs: 
        - ExperimentsDVC/data/processed/features.csv 
        - ExperimentsDVC/data/processed/labels.csv

    
    train:
        cmd: python  ExperimentsDVC/src/models/train_model.py
        params:
            - train.n_estimators
            - train.max_depth
            - train.min_samples_split
            - train.min_impurity_decrease   
        deps: 
        - ExperimentsDVC/src/features/feature_engineering.py
        
        metrics:
            - metrics.json:
                cache: false
        plots:
            - dvclive/scalars:
                cache: false    
     
