## [PIPELINE STAGES](https://dvc.org/doc/user-guide/pipelines/defining-pipelines#defining-pipelines)

# What are stages ?

## Each one of the data workflows that
## we reproduce reliably to ensure consistent results.
## Might include Feature engineering , train , evaluation

# How are stages defined ?

## The stages entries are
##    cmd: python path that wraps executable shell command.
##    params: loads parameters. Related to params.yaml file
##    deps: dependencies. Might contain Stages that might be executed first
##    outs: outputs, they can be data or even the model

# What do you need to set up your experiments ?

## For setting up the experiments, we are going to follow the data science
## cookie template and we are going to use the folders already given. 


stages:
    load:
        cmd: python src/data/load_dataset.py 

    featureengineering:
        cmd: python scr/features/feature_engineering.py
        params:
            - features
            - labels 
        deps: 
        - src/data/load_dataset.py 
        outs: 
        - ExperimentsDVC/data/processed \
    
    train:
        cmd: python scr/models/train_model.py
        params:
            - n_estimators
            - max_depth
            - min_samples_split
            - min_impurity_decrease   
        deps: 
        - src/features/feature_engineering.py
        
        metrics:
            - dvclive.json:
                cache: false    
     
